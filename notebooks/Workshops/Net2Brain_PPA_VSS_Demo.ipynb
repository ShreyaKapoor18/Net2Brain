{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PhXmDhmt6Gd8"
      },
      "source": [
        "# Installing Net2Brain and Relevant Dependencies\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vPQh1MlxCtCT"
      },
      "outputs": [],
      "source": [
        "# !pip install -U git+https://github.com/cvai-roig-lab/Net2Brain"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OtrlzxH1sbn-"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "## Restart Runtime\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<img src=\"data/Net2Brain_Logo.png\" width=\"25%\" />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nWzawRYH6oQ_"
      },
      "source": [
        "# Net2Brain"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dn_2AvR-5ah7"
      },
      "source": [
        "__Net2Brain__ allows you to use one of over 600 Deep Neural Networks (DNNs) for your experiments comparing human brain activity with the activations of artificial neural networks. The DNNs in __Net2Brain__ are obtained from what we call different _netsets_, which are libraries that provide different pretrained models. \n",
        "\n",
        "__Net2Brain__ provides access to the following _netsets_:\n",
        "- [Standard torchvision](https://pytorch.org/vision/stable/models.html) (`Pytorch`).\n",
        "This netset is a collection of the torchvision models including models for image classification, pixelwise semantic segmentation, object detection, instance segmentation, person keypoint detection, video classification, and optical flow.\n",
        "- [Timm](https://github.com/rwightman/pytorch-image-models#models) (`Timm`). \n",
        "A deep-learning library created by Ross Wightman that contains a collection of state-of-the-art computer vision models.\n",
        "- [PyTorch Hub](https://pytorch.org/docs/stable/hub.html) (`Torchhub`). \n",
        "These models are accessible through the torch.hub API and are trained for different visual tasks. They are not included in the torchvision module.\n",
        "- [PyTorch Video](https://pytorch.org/docs/stable/hub.html) (`Pyvideo`). \n",
        "Offers models for video analysis, including action recognition and motion classification.\n",
        "- [Unet](https://pytorch.org/hub/mateuszbuda_brain-segmentation-pytorch_unet/) (`Unet`). \n",
        "Unet also is available through the torch.hub.API and is trained for abnormality segmentation in brain MRI.\n",
        "- [Taskonomy](https://github.com/StanfordVL/taskonomy) (`Taskonomy`). A set of networks trained for different visual tasks, like Keypoint-Detection, Depth-Estimation, Reshading, etc. The initial idea for these networks was to find relationships between different visual tasks.\n",
        "- [Slowfast](https://github.com/facebookresearch/pytorchvideo) (`Pyvideo`). \n",
        "These models are state-of-the-art video classification models trained on the Kinetics 400 dataset, acessible through the torch.hub API.\n",
        "- [CLIP](https://github.com/openai/CLIP) (`Clip`). \n",
        "CLIP (Contrastive Language-Image Pre-Training) is a vision+language multimodal neural network trained on a variety of (image, text) pairs.\n",
        "- [CorNet](https://github.com/dicarlolab/CORnet) (`Cornet`). \n",
        "A set of neural networks whose structure is supposed to resemble the one of the ventral visual pathway and therefore implements more recurrent connections that are commonplace in the VVS.\n",
        "- [Huggingface](https://huggingface.co/) (`Huggingface`). \n",
        "Features a broad range of advanced language models that deal with text-input.\n",
        "- [Yolo](https://github.com/ultralytics/yolov5) (`Yolo`). \n",
        "Includes fast, accurate YOLOv5 models for real-time object detection in images and video streams.\n",
        "- **Toolbox** (`Toolbox`). \n",
        "A set of networks that are implemented within Net2Brain.\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "---\n",
        "\n",
        "**Net2Brain** consists of 4 main parts:\n",
        "1. **Feature Extraction**\n",
        "  > Handles input in the form of images, videos or text and extracts relevant features for analysis and saves them into .npz files.\n",
        "2. **Representational Dissimilarity Matrix (RDM) Creation**\n",
        "> Utilizes numpy arrays (.npz files) from the feature extraction process to create RDMs that quantify dissimilarities between data representations with different distance metrics.\n",
        "3. **Evaluation**\n",
        "> Provides a comprehensive suite of evaluation methods including Linear Encoding, Representational Similarity Analysis (RSA), and more, to assess and compare model performance\n",
        "4. **Plotting**\n",
        "> Offers advanced visualization tools to graphically display the results of various analyses, enhancing interpretability and presentation of findings.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UqQdckZHWVR4"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pbm36FteFXql"
      },
      "source": [
        "\n",
        "# Step 0: Exploring the Toolbox - Model Taxonomy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mhM7X2FXF2AI"
      },
      "outputs": [],
      "source": [
        "from net2brain.taxonomy import show_all_architectures\n",
        "from net2brain.taxonomy import show_all_netsets\n",
        "from net2brain.taxonomy import show_taxonomy\n",
        "from net2brain.taxonomy import print_netset_models\n",
        "\n",
        "from net2brain.taxonomy import find_model_like_name\n",
        "from net2brain.taxonomy import find_model_by_dataset\n",
        "from net2brain.taxonomy import find_model_by_training_method\n",
        "from net2brain.taxonomy import find_model_by_visual_task\n",
        "from net2brain.taxonomy import find_model_by_custom"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7TKygwloFdk0"
      },
      "source": [
        "To view a list of all available models along with the information on which netset they belong to, you can use the `print_all_models()` function to print them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NCgzKdvJyzMQ"
      },
      "outputs": [],
      "source": [
        "show_all_architectures()\n",
        "show_all_netsets()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SIRFVwUj5tiq"
      },
      "source": [
        "You can also inspect the models available from a particular _netset_ using the function `print_netset_models()`:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eNrc9U0kToEo"
      },
      "source": [
        "We also offer a comprehensive model taxonomy to help you find the most suitable model for your study. Each model in our toolbox has distinct attributes that cater to various research requirements. To facilitate your selection process, we provide a taxonomic overview of the models available.\n",
        "\n",
        "To see the available attributes, use the show_taxonomy function. You can then search for a model based on one or more attributes using the following functions:\n",
        "\n",
        "- `find_model_like(model_name)`\n",
        "- `find_model_by_dataset(attributes)`\n",
        "- `find_model_by_training_method(attributes)`\n",
        "- `find_model_by_visual_task(attributes)`\n",
        "- `find_model_by_custom([attributes], model_name)`\n",
        "\n",
        "This taxonomy system is designed to help you easily identify and choose the most appropriate model for your research needs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hO5e2wMlTItN"
      },
      "outputs": [],
      "source": [
        "show_taxonomy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RTLc3ybMShcf"
      },
      "source": [
        "Or you can find a model by its name using the function `find_model_like()`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9t0J7tIrSerQ"
      },
      "outputs": [],
      "source": [
        "find_model_like_name('ResNet')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFJtD7dUX5o2"
      },
      "source": [
        "The `find_model_by_dataset(attributes)` function enables you to search for models associated with a specific dataset, such as 'ImageNet', 'ImageNet 22K', or 'COCO'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ggT2UcQ0SNXs"
      },
      "outputs": [],
      "source": [
        "find_model_by_dataset(\"Taskonomy\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqDPsOQ2X7TK"
      },
      "source": [
        "The `find_model_by_training_method(attributes)` function helps you discover models based on their training methodology, such as 'Supervised', 'Jigsaw', or 'NPID'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ReNMFkHwSQI3"
      },
      "outputs": [],
      "source": [
        "find_model_by_training_method(\"SimCLR\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WIfluynEX84g"
      },
      "source": [
        "The `find_model_by_visual_task(attributes)` function allows you to search for models specifically trained for a particular visual task, such as 'Object Detection', 'Panoptic Segmentation', or 'Semantic Segmentation'. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Su3z7_0CSUwf"
      },
      "outputs": [],
      "source": [
        "find_model_by_visual_task(\"Panoptic Segmentation\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5aYEbqWkX-Ui"
      },
      "source": [
        "The `find_model_by_custom([attributes], model_name)` function enables you to search for models based on a combination of the attributes mentioned above. You can provide a list of attributes to filter the models, and optionally specify a particular model name to further refine your search."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wzeDdnGgSZg5"
      },
      "outputs": [],
      "source": [
        "find_model_by_custom([\"COCO\", \"Object Detection\"], model_name=\"fpn\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Q4Eb8lHWT8D"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hu01QjhzNRgQ"
      },
      "source": [
        "# Example Study: Exploring the Function of the Parahippocampal Place Area (PPA)\n",
        "\n",
        "The Parahippocampal Place Area (PPA) is a scene-selective brain region in the late ventral pathway. It is believed to represent abstract relationships between scene elements, such as individual relations between objects. However, recent research suggests that the PPA is more focused on understanding how the parts of a picture are arranged or put together, rather than just their meanings or purposes.\n",
        "\n",
        "\n",
        "We aim to test this hypothesis using `Net2Brain` and two popular computer vision tasks, comparing neural representations with model representations for scene classification and scene parsing tasks.\n",
        "\n",
        "**Scene Classification** identifies the scene category by considering the entire scene as a single unit. The network learns to recognize global features characterizing different scene types.\n",
        "\n",
        "**Scene Parsing** provides pixel-wise labeling of the entire image, encoding the spatial organization of objects within the scene. This process allows the network to gain a comprehensive understanding of the scene.\n",
        "\n",
        "![SceneParsing_Classification.JPG](data:image/jpeg;base64,/9j/4AAQSkZJRgABAQEAeAB4AAD/4REwRXhpZgAATU0AKgAAAAgABAE7AAIAAAAiAAAISodpAAQAAAABAAAIbJydAAEAAABEAAAQ5OocAAcAAAgMAAAAPgAAAAAc6gAAAAgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAEJlcnNjaCwgRG9tZW5pYywgU0VWRU4gUFJJTkNJUExFUwAABZADAAIAAAAUAAAQupAEAAIAAAAUAAAQzpKRAAIAAAADMTQAAJKSAAIAAAADMTQAAOocAAcAAAgMAAAIrgAAAAAc6gAAAAgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADIwMjM6MDQ6MTkgMjA6Mjk6NTgAMjAyMzowNDoxOSAyMDoyOTo1OAAAAEIAZQByAHMAYwBoACwAIABEAG8AbQBlAG4AaQBjACwAIABTAEUAVgBFAE4AIABQAFIASQBOAEMASQBQAEwARQBTAAAA/+ELNGh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC8APD94cGFja2V0IGJlZ2luPSfvu78nIGlkPSdXNU0wTXBDZWhpSHpyZVN6TlRjemtjOWQnPz4NCjx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iPjxyZGY6UkRGIHhtbG5zOnJkZj0iaHR0cDovL3d3dy53My5vcmcvMTk5OS8wMi8yMi1yZGYtc3ludGF4LW5zIyI+PHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9InV1aWQ6ZmFmNWJkZDUtYmEzZC0xMWRhLWFkMzEtZDMzZDc1MTgyZjFiIiB4bWxuczpkYz0iaHR0cDovL3B1cmwub3JnL2RjL2VsZW1lbnRzLzEuMS8iLz48cmRmOkRlc2NyaXB0aW9uIHJkZjphYm91dD0idXVpZDpmYWY1YmRkNS1iYTNkLTExZGEtYWQzMS1kMzNkNzUxODJmMWIiIHhtbG5zOnhtcD0iaHR0cDovL25zLmFkb2JlLmNvbS94YXAvMS4wLyI+PHhtcDpDcmVhdGVEYXRlPjIwMjMtMDQtMTlUMjA6Mjk6NTguMTM2PC94bXA6Q3JlYXRlRGF0ZT48L3JkZjpEZXNjcmlwdGlvbj48cmRmOkRlc2NyaXB0aW9uIHJkZjphYm91dD0idXVpZDpmYWY1YmRkNS1iYTNkLTExZGEtYWQzMS1kMzNkNzUxODJmMWIiIHhtbG5zOmRjPSJodHRwOi8vcHVybC5vcmcvZGMvZWxlbWVudHMvMS4xLyI+PGRjOmNyZWF0b3I+PHJkZjpTZXEgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj48cmRmOmxpPkJlcnNjaCwgRG9tZW5pYywgU0VWRU4gUFJJTkNJUExFUzwvcmRmOmxpPjwvcmRmOlNlcT4NCgkJCTwvZGM6Y3JlYXRvcj48L3JkZjpEZXNjcmlwdGlvbj48L3JkZjpSREY+PC94OnhtcG1ldGE+DQogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgIDw/eHBhY2tldCBlbmQ9J3cnPz7/2wBDAAcFBQYFBAcGBQYIBwcIChELCgkJChUPEAwRGBUaGRgVGBcbHichGx0lHRcYIi4iJSgpKywrGiAvMy8qMicqKyr/2wBDAQcICAoJChQLCxQqHBgcKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKir/wAARCADIAZcDASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwD6RooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKAGmuVt/E18jN9otYp4xIygxNsYAMR0bg9PUV1Zrgofuv8A9dZP/Q2ryczxNTDQjKm+p2YWnGpzcyOntfEum3L+W0xt5f7lwuwn6E8H8Ca1QwOCDkHpXDMquhVwGVhgqRkGmwLJZkfYLia1C9Ejb5P++Dlf0rio53F6VY/cazwa+yzvaK8xtPihqgWSdfDt5qumIWxf23lxlwpILLEz7nHB5GM9geK7LTPF2k6rbwTQ3PlLcRrJF567NwYZGCeDwexr3IYilNaM45Upx6G5RTVYMAQQQehFOrcyCiiigAooooAKKKKAGSlxExjUM4UlQTgE9hmvPtN+KEym8PiPRfsYtpLhD9iuPtJC25AnkbKphF3J0yx3cDivRKxbrwhoF4uLnSreUee853L1dyC5PqGIGR0OBQBRtviFoU17NbXUraeEaRI5r0rFHOY5TCwRi3PzjGDgnIxml8FeK5/FFpdPe6a+l3Fu6g2k2/zUVl3KXDIuCQe24deat6P4Q0jRpLma3thJcXUssss0oDMfMlaUr6ABm/QZyeat6VoOmaFDJFo9lHapKQXEY64AAH0AAAHQDgUAc5F8UNHnlt4obLUWmuphFbReUm6bLSJuHz4ADRODkg9DjBzVG4+MWgyaXdXGkw3V/cwwSzx26BR5kaRly5bJAXGMg/MM4254rd0PwJomiQwrFa+fNDMZkuJuXDbpGGPQDzX4HHzHuc1LL4E8Mz2pt5dHt2iJPy88AqVKg54XBI2jjHagDGsvibZXguI47C7nubdpRJHarvEarI0as5OMBmjYZAIGCSQOaraf8Y/D91p8Ml1HcW909rFM9su2Rg8iI6xjBySRKmCQFOcZyCB0v/CFeHPMST+x7bckjSg7erFt5J9fm+bnoeRSJ4I8Nx27W66Rb+S0QhMZBK7QFA4z1ARRnrhVGeBQBnN8QrKz8NrrGqWVzbI1/PZeV8uUMcki5diQijEZP3sZIAJJGS9+Jei2AneeG9+zxSCFLnylEMsm5V2LIWCggsPvFRw2CcGtdvCehvpa6c2nx/ZFleZYwSMO5Yu2c5y29s887j61E/gnw487zHSLYSsAN6qVKY2kFcfdPyJyuD8o9KAMeT4q+HoleSRbxbdYhJ9oMQ2EmBZgn3s7ijdxgEEEir6ePdKm0C01S0iurpbyd7aG3hjVpXkQOXUfNtOBG5yGIIHBORm6/hDQJI2jfSrdkbgqV4P7ryv/AEWNv0qSfwzo9zpKaZPYRvaI5kWMk8Mc5bdnOTubJzk7jnrQBzV78UtMh1BrKzsLy6uY7iCJ1+RMCSVYyeWyCpYAqwB5HbJAnxd8OTaXJf2iXl1GivKVgjVmMSRmRpMbuBtHQ4bOBtrci8D+GoHd4NHt4mfGTGCuMOHGMHjDqG4789zWbrnw00HWNJXToo20+3BfItUTJVozGVBdW2jDHAXA/DigBkvxO0VXEaW99K8knlWwSJf9JYTpAwQlgPlkdVO7HXIyBmq1n8WdEeeS1ukmjuo2n3RRAOQI3lUDHDMx8lvuggHAzyM9BF4N8PxXH2hdLg87cr+YV53K6uCPQ71VjjqQCc0o8HeH1kdxpVuC4cPwcPvLlsjocmSTr03tjqaAJ/D3iCz8S6QmoafuETMyEOykgg4IypI/ImtSqmm6XZaRbNBp1usEbOZGAJJZj1Yk8k+5q3QAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAJXBQ/df/rrJ/wChtXe1wUP3X/66yf8AobV4Gd/wY+p34L7RJSqSGBHBzxSUq8MM+vevlT0TitO1L+ytBm0qC/vcwgx2M7aFdkwx9gw2YcryARgHAz3rptHtLez0Cxs7Yu9tFbRxp5yFWZQoALKQCD6ggfSvNPDtvqcWt2FrGn2QvcpI00mpxOZWiaRbg+WrkszqUDLj5WBz0zXrNd+LSg7Re+v9WMaTvqRwxvZgDT55bPByFib5f++Tlf0rTg8Rahb5+1QRXa+sR8t/yOQfzFZ6MJE3RkMp6MpyDS0qWPxNDaWnmVKnCp8SOs0vVoNVhd4FdGjbZJHIuGU4Bx6dCOlXq5vwj9/U/wDr5X/0WldJX2mHqOrRjOW7R5FWKhNxQUUUVuZBRRRQAUUUUAFFFFABRRVbUDeCxlOmLC10FzEs7EIx9CRyM9M4OOuD0oAljnjmjDwusiEkBkYEcHB5+tOLV5jF8O/Ef/CQ296+r+XbrbsTDFdMEjmO5woTZ8yiUq27cudvK07Wvh/4q1CKzaLxAxuYbjMkq3DQkx8FW+4wLKxkwABkMPmGKAPSop450DwusiN0ZGBB/GoZtTsre8htJ7uCK5nBMULyhXkA6lVPJ/CvNh4E1bTUkUXc/wBpv75Yd9rI7JHZtEElVs4CY+dww/iCevHS694c1K/8R2l3YQ2IgXyPNnklPmBY5C+3yyjK+c8HKMpOcnAoA6uOaOaNZInV0cBlZTkMD0INODA9K8wj+HGvWQtYbG9jNrEiYR7+dfIm8uJWuFxncQ0bkI2FO/qOQd3wDoeraZ9putVYxJdRxhbc3Mkp3KXJkbf9xiGVSq8ARjnsADs6KKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKAErgofuv/ANdZP/Q2rt7e8tryHzbOeOePJXfE4YZHBGRXEQ/df/rrJ/6G1eBnf8KPqehgt5GLc+M9Htb+4s2N9LLbP5cv2fT55VVsBsbkQjOCO/etDR9ZtNct3uNOMrJHKYnWWB4mVgAcFXAPQjtXK3WsDwxrupi1u9Fu1vbgXEkNzqyWstvJ5aKQQwOQQikdCMng1ueEVRtNnu/ttpdzXd288z2MwlijYgAIrd8KqjJxk5OBnFeFUowhT5ku3X7zrUm5WZw2kWejpqmlpPqzSt5lv9jdLF0HlRPJ5e5iTtMshJ3fx7eOtd94ptLu+8LX9tp243EkeAqttZ1yNyg9iVyAfeuEsjpOk6hbtfXGjGD7XAEP/CQGVotm4RKEEI+Vd7EBjgHBJ4Fdvr6Sah4JuybqGzaW2DvMJiYlHBYbwAdhGRuA6HOO1b4i/tYP8/8AgEQ0izk30l9ZZ7/TNHmtCs1ta6UjxrH9hjjbfLIVz8m7LLgZLAAdDXo/YVxHhC60bUvED3fh2CzsI4rHyrq0gheFmlLjkqUTITaVDYyd56Yrt658XJ83K+n9foaUlpc1vCP39T/6+V/9FpXSVzfhH7+p/wDXyv8A6LSukr7LBf7tD0R5WI/isKKKK6zAKKKKACiikZgilmOAOtAC0VBaXttf2yXFjcRXMEgyksLh1YexHBqegCtqN6mnaXdXsis6W0Lysq9SFBOB+Vc4/wAQLCwtjL4gt7jSztikRSvneYsgcgr5eTwI3zxwBmumvLWK+sZ7S4G6KeNo3GcZVhg/oa5Wf4Y+HrzSjY3y3t2pdHE1xfSvKuxWVVDlshQHfgcfMT15oAkl+JXhqG1u7l7yYw2hYPIlpKyvtfYxQhcOA2ASuQMjPWoX+KXhxbiFYnvJ4JF3faorGZoh8qsBuC8kiROBn7wHeobf4V6KLW6ivpbuczXUk8ZS6ljFuGkZ9sYDfJ1AJGN2ATV+L4d6BBYWdnDBOkFnIJIlW4fnCooDc/MMRpwe6g0ARSfE3wxFbtNcXdxCEZVKyWM6tyH52lM4HlyBj0UoQcGpD8Q9FbUI7K2+1TzSXq2a7bWQKWLMhYMVAZAyEFlJA455pNX+G/h3XI9uoWsjYbcGS4dGB3SNwVIPWaT8x6CrZ8E6N9ot51hlSS2laaJlncbWMxlPfuxP4HHSgCpq3jy20e+v4LqxuStlC0pKFGeTagYlYw28rzjcBjOc4HNSf8LA8PrJsM90G83yVzYzAOfmyVJXlV2NuYcLjkipr7wVpWpX1xc3jXr/AGhHVoftsoiQvGY2dU3bVYqSMgdyepJqO28BaJa3ZuBHcTOXZwtxdSSqm5XDBVYkKp81yQMDJHoMAGhoPiPTvEti13pEzSxI/ltviaNgcA/dYA8ggjjoa1axvDPhXTPCWmtYaLHJFbtIZSJJWkOcAdWJOMAD/JrZoAKKKKACiiigAooooAKKKKADIorzLxr4713RfEU2naBHbXEqGLbBMmCwYZO1sjJ54HrWND8VtemhVwtou4Z2tCQR7daHoC1PZqK8cuPih4ghtTPi02jH/LE+v1pjfE/xMM4SzP8A2xP/AMVSuVys9mzRXiy/FXxIGPmW8JUD70duWA/8epLb4qeJLkMY1syAcf6gj/2alzJD5Gz2qivG2+J/iJFYMLPeMceUeM/jT4fib4ikj3lbTGcf6k/41HtI83KV7KVrnsNJXkn/AAsbxKw4htVGepiOSPpupZPiV4hTH+j2gXOCzKR+VXzIXs5HrVLXkZ+JuuLz5dqRtycxlR/PP6Vm3nxpvrViGmsSwO3ZFC0jbuwwCT0zS50LkZ7dRXNeAtfuvE/hODVL5BHLK7goEK4AYgcHoa6WrIOb8Zapqmm2mnRaJLbwXV/qEdoJbmEypGGDEnaGUn7vqKrrpPjon5/FWkr/ALuhv/W4p3jf/XeGv+w7B/6BJXVUAfOmieAviJefFPV9Z8PaudB0yS6LS3ZtjFHesOHdbYs24EhjliAc5B5xXpVorpb7ZX8x1dwz7cbjuPOO30rvwMVwcPR/+usn/obV4GefwY+v6HoYL7RxXiW41y81uSxt9DvItLUYku7JoDPc8dFZ3Xyx2zgsccbetdH4Xgt7fR0hstGk0eKN9q20uzcf9rKM2SfUnPrXEeLLbRNR8SXNmfD6wz/KbrWJ9IluN2QOIgiMGbGOWwo/2q7DwXp2jaV4fjtPD0c0dokh3G4hkid34yxDhTz7AD0ryKySw8dLf16s6Y/GzmLe7m1C90+XVI5m0e4ukNpdTWNsElfP7s4U71DHoSO4zium1LQ4U8Dto8azPHBbJHF9njBfKY2kKTzyo4zyOK4zRtfhaXTbK6s7F1jv4ZYLWGeQtAZjIuAjMRuidDkYwAcqFwK7zxNdpY+Gry4kkuI9qAK1swWTcWAUKSCASSBk0YjnjUjFaaihazZzXhGGRPF1698LyO4kSa4hims/JULLIhk+be287lQY7D613VcH4KlmfxHcpq32uW+iSeCGSa+FwgWOSMSADy0wdxjOcHI9MYrvKwxl/aa9i6VuXQZpVj4hurzUG0PW7TT4RMoeOfTjcFm8ted3mpj6YrSOkeOe3izSvx0Nv/kip/CP39T/AOvlf/RaV0lfZYL/AHaHojy8R/FZyX9lePO3irR/x0N//kij+y/H3bxPop+uiSf/ACTXW0V1mByP9m+P/wDoZdC/8Esv/wAk0v8AZXj09fFGjD6aJJ/8kV1tFAHKLpPjn+LxZpf4aG3/AMkUp0jxkFzJ4tsAB1I0bH85jXVUEZoA+d/Avw++If8Awnmo65pOsP4f0O5vXmAlgwLxSxywtScLu6/NgjIxX0OuQo3HJx1x1pRRQAUUUUAYvivUrjS9E+0W08drmeKOS6kj3rbxs4DOR7DPJ4HU8A1xEfjfXb6yWPSZVkc3MiLcziLDxrtIwYi6Ofm2llIHUbQRXpwkSR2QMpZeoByRS7OOKAPOvEHjTULHQNFv4tTs4WudP+0yKiqxmkwhHlhyokXlsorBzlcUo+Imo2UDLqNvYIXnlENzc3JhiCLLOo3nYdp/cqoxnJcd+D6EoVhx0B49qTzIyxAdMqcEZ6GgDkPCXjyXxNrL2T2UUG1JmYJOXkgMcioFlXaNhbdkc87G/DtKrWdhb2Uci2sYjWSV5XA7uzFmP4kk/jVmgAooooAKKKKACiiigAooooAKKKKAPCviTo+pXPxKluLK1uJImSIF0jJX7oHUVxM8s8d06opAjkKlQwAOG+noDx79a9k8XaneQ+KzaWs8NvHsjdmYZdsMpKgdMFA4z1zivHNS8LW9x41vbi/1FLO32xlRtkyxdpP7hH9zr9PShtWuJJ3LMeqGB1Ux743X50R/vexyOKlm1lkjZn3qAu7aUBHbjrnpk1jy6NpIs7G7tZ9QDXM7wlBfMQuApB45zz0zUzaFei+sD/aljPHLbPI9vBfvLJGAoILqR8p+Ydz/ACqIyjJ2SNXzrqbUBuLuKGeEBUKhuMkMDg57dqqWc5h85AXXeWwVXOD659vSvQ/C2kQ32jRiBOEhXI7Y25GO+Pr6VyWmaNLNYXF/uUW8MpR+eQSMg/Sk0nJWLUrRd2VSqG2LpGULMNzMcsx9/wClX9L8RW2kQNBOhDElt6qCcccZP0NRRxiayjZL5L5XAZZFxwMdOK5/X5LizndoNpMce4KVzng1z8yVTmZ0cjcOU6SbxfHeKw0vS5pT/wA9HQRrn3Zjn8gaosmt6hE5LW1kD1MCmVwP95sD/wAdNZGj6tbaT4Nur/VGlV2vpILcFGkyAo5JA4HB9K3dN8YaTNpAisJY72/kkWOOzQ7Hcn3fAGPrTlOTdkLkUdzLfw359sJNQknu+fuzTE/mowv6Ve0zRUVTb2dvHEh5KogXpXdWekiSzsf7Qt1tZ5Bvnt2lV9nzEYLDjtWXZfZbe5u186OKOB5OS/3UUbs59AM1yyrLn5GdEaV4cyPQvhvF5PguBCMfvZD/AOPGurrlPhzd2t74QjuLC5W5geeXDqcjIYgj866uvTj8KPLl8TOV8b/67w1/2HYP/QJK6quV8b/67w1/2HYP/QJK6qqJErgoej/9dZP/AENq72uCh+6//XWT/wBDavAzv+DH1O/BfaJKUfeH1pKB94cZ56V8qeieY2+laobizNjcXOn3nnp5skXhoRRoufmAk8vOMcDPUda9DMEOp6T5F9F50NxCFljljKFgRzlTyp9uorgtK0po73S447S1t9St7sPd6ul9HI10uTuGA29t/wDdYALnj7or0iu/Fy1Vv0/QxpLRmbp3h/TNJvLi7sLUR3Fycyys7Ozc5PLE4GeeO9aVFFcUpSm7ydzZJLY1vCP39T/6+V/9FpXSVzXhBlY6mVII+0gcHP8AyzSulr7zBf7tD0PGxH8VhRRRXWYBRRRQAUUUUAFFFFABRRRQB53J4T1yDTZoNN03TbW82mN9SgvJIp7oNKrMxZFUqxALHJb5jjkE5gg8I+NItLgaXWppL0BEuA2pTbJYlhjDKDj5WZ0f94BuG7PtXceINdt/Dukm/u4pZU82OEJEUDFpHCLy7KoGWHJIFZNv8QtDnsGuHlkidVlZoNnmOvllgRlCy8mNwuGO7acZwaAM3w1pOs6f4hitLlriOyiSa8kUXEsiCWSaXYnmMB5g2Pkj+8gY8nJyZfh5rEmsSXNvHa2qG6W4DJcncW+1Ry5BVFYjaHJWRn+YgAgc11moeNdP02TTla2vJjqMPnReXGAQvH8LsrM3zD5EDN7Ulv8AEDw/PYyXT3jQLFIYnSWJtwILjoAcj925yMgBWzjBwAc1D4R8aHezavLAFs5Vii/tSaUG4KxAOzHB2krLheiZyBk4HY+FLLVNP0JINbmMtyJJCMzNLtQsSq72+Y4GOpJ9zUul+JtI1q5mt9Lvo7iWEsHCggHaxViCRhgGGCRnt6itWgAooooAKKKKACiiigAooooAKKKKAPCfiHrbWHxLvIZpysayWBRTnABDlun0/QVx3imdZ9e8g3ZtmMELEqMklJJWAJHIGcdKs/GmcJ8X7hX3hVitXzGhYkhWwOPr3/8ArVHaae+p6szRwX13JcfvEVYYmKqT0bcVOABjhs1MpK1ioxd7mE1y40PTYn2xqtxJlmcYA2rjnj0xWg2rpb+UFaHzI7cxOwjK8cLjPOePar11p1rBdWserfIApkiBsTDGDzyG2gN25DfpVSXRRqOjxR2ep28s4UAlZEZicc/cB4Pua59Yv3lY3Vvsu5mx+LtV0+2vP7L8wTuphNxE5dm+6VI57YPTNdpB4t03SPD15o9xJIl5eHzo2CZUKFIySOevpzXBweEtaWf7JZ2UhuF/eDzWEfy54Iz1GaTUfCfiC+t4JJLaKeeMtuIlUYXJ9fQEj60UVy2aZdabrTfOv66Hc+EJIrnTYoBdRXLRJh3iLY3dTncAe/fr1rL8S6ha2njKOxvoYpofKyFH3zlfm/TH60ngHw/qelxTrdJ5KnBy0gJJ/D2ArD8Z+FtQ1Hxbc3UE8ILeWsTNI3A2AH+E45x096rnTlqKSbgrFq+1HTrzw2sVtZrC8d4iyIcsxVlLEkA/L6Z7YPriuz8ARaNd2wh1O1kkWSEMJIDxhVB5TGRzj9K4DTPDt2rSzX11YoJV2SuZXVyfocA/p9a6SK50zQdIjnuL13mVG+S1Od33d2CGOTtUcE9/ylO7tEialbXcn8V3WlXOoCWcW5SPTY54o5Wd8FnbJDrtG3cwAzyeMisDS9UvLdLmHS7SKMXVvMQAMoSwRWxknbgFu/UVW/tDRJ7yePSTZqs/7qFZpjDsiGGAdZAA3zDkKeRx35kvYtR1KbT4o5lkXT7ZkjSKVFEJZt2NhHIPHIz264rXljy3aMHKd7Jn0P8ACm2+yeA4IgYyonmKmJiykFyQckDNdnXl/wALfEekaH4DtrPX9ZsdPu/OmfyL27SOQKZDg4Yjjj0xXY/8J34R/wChp0X/AMGEX/xVaLYRU8b/AOu8Nf8AYdg/9Akrqq4DxP4n0DV9Q8NW2la5pt7P/bcLeVbXccjYCPk4Uk45rv6YCVwUP3X/AOusn/obV3prgofuv/11k/8AQ2rwM7/hR9TvwX2iSgdR/So1nWWXyrcPcSf3IVLkfXHA/Eir0GiatdrkrFYqT/y1PmP/AN8qcf8Aj1eBRwVet8ETulOMPidjgz4ZvrrVLGZtF0DTFtbtbk3NoS8rBc/KB5S43ZwTnj611guUeTy7cPcSZxsgQuR9cdPxro7fwtZK268aa8bGMSthP++RgfnmtmG3ht4ljt4kijXoqLgD8BXuxymdSzrS26L/AIJxvFQj8KucpBomq3JO5IbNOxlbzG/75Xj9a0rfwrZKyteyTXjr2kbCf98DAP45rdwKMV6dHAYej8MdfM5p4ipLrYigt4raMRwRpGg6KigAfhUtFFdxzhRRRQAUUUUAFFFFABRRRQAUUUUAUNZ0az12wWz1GPzYBNFMUOCGMbhwCD1GVGR3FZF74A0G91aPUHs0jljgFuBGigBF37QOMrjzG+6RnjOcCumooA5/U/B9nq9nFa3t3etCtuLaVFmAWdBj7wxgNx95Qrc8GoZPAmmNCqQz3lu6rtWWGba4GZiRnHf7RJ+hGCAa6aigDmPCvgq28MF3Sd533ziAE/JBFJMZNij/AL5ySTnb2rp6KKACiiigAooooAKKKKACiiigAooooA+c/ivb4+KV9Kv32htwSfTbjH61Rj8SS6Jflo7aO4SaBoZFdip2k84I6Eg11fxEshP8Q7tj1aOIdfRRXDeJLdYJIeACxbIzn0rhqz5LtPU9CjDnspLQ3ofGGhzazFqVzbXlrcJEsKRtiWEKPoQRx6D9auwf8IvcQKv+iaiqTSzeRJAkiyhxnaN+H3AgHIGeorzl+31FOfa4AkG761H9oVWrT1LlllG94XRv6Zp8k3jGWzbTpbmwErRLDFK0awfOeR0GBxxjp6V09p4EhvvElw9/ax2duCcRzRKsSJkkAOSQ7fdGQPu5zg15vE7jcqyyBQ3CiQgDge9OYZ+8SfqxNFPHKC5eVGVTL5TnfnPXV0Hwlp2oWz3+k6BMjRFJ9ohwrbiVYAv6HB9x+XPa/wCGPBvkpdW13oAuMnzoxIuB8y42opC5wG6sOo9MV59KibG+RenXFVmUbRwOmf0qljn0iif7OVrObO9kfwtpOmpCt9ot6+0GQxWSo27IPXacgEeoyD26nB8S+KbG5sL/AE3Roo9l3cFg6qTHBH5aLhARnJ28nsB3zmuYYZP1plh/yFot2MbyeenSlLEyn0NKWEjTd73My4tmchyglVT94AHH+H6VUWJNjMkPRvvRsQVrutQ0u2uQWWJ4JT0lQ4rlr3SZ4UJKibknehwx9yOh/Cs6dRS0OirB7pH0z8Bf9L+EtjJdHz3FxOoaT5jgSHAya9J+y2//ADwj/wC+RXnHwATy/hHZKM8XNx94YP8ArDXplelHZHky+JnI+NII47jw0Y0VT/bsHRQP4JK66uV8b/67w1/2HYP/AECSuqqiRCKxYvCmnqzm5826DOW2TP8AIuSTjaMA9e+a280ZFRKEZ/Er2KjOUfhZHDbx28SxQIscajCoigAfQCn4paKskKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACgnFFFAGBP420K28QNotzdSw3qKXcSWswjVQMljLs2bffdjPHWtCLXdKmnghi1KzeS5UPAi3ClpVOcFRnkcHkehrH8SeC4PEd3LcS3ckDSWq24CIpClZlmVsHg/MgBB6jNYVr8MXj8S/apr/NmPJmPlxqskky3FxO2MD92u6ZcbTkjIPrQB2MfiDTpdel0WKZ3voUDyIsLlUBGRufbtBI5wTmnX/iDS9MvbWzvr6GG5u3CQQlsu5Oew5xweenvWHp/gG10/wAUQ6xHdyyGANsEqh5mJjCHzJzmSRcDIDk4OOcBQK3iT4bWviPWJ72a/mgjuhH58SRqWJRJEUq55XiU8c8ge+QDdPi/w+LmKD+2bEvNBJcJi4Uq0aEB23ZxgE+vr6HD77xVoWmWj3N9q1nDElubokzKSYv74A5I9xXGP8HbN9PitzqtzuQNufnLZeB1OS24YNsn8XQsBjjEr/CS0eyktBqkvkTWpgk328cjljE8e5XbLKMSE4B7dcE5AOyHiHR2hllGqWRjgCtK/wBoTEYb7pbnjORjPWp9L1S01rS7fUdNlE9pcJvikAI3L64PNcSPhParqkmojUpvtP2n7VHlN0auZfNYFGYjaWJwBjAxySM11nhnQ08N+GrHR4pmnSziEYldQpbHfA4FAGrRRRQB4/44WQ+O7rZjBjj5J/2RXnnie1uFYXMyu4LEARDeVGOpA5x9M16R41c/8J7OmFxsjyT/ALorKltUuiQ2CM9u1ePipyTaPawqXKjysuskYkjZZE3DLIcgc9D6fjSk5xXbav4JtrpvPhDLMP8AlpESj/mOv45rkb7SNT0923Ri7X1VfLcfh90/pXGpKWmzO7YpxN+8b/e/oKkLDqDWcL1ElYGO5BJ+6YTkfnx+tI97L/yxtJ356uVX+RNaKnIwc1cvTP8AI30qqzgZFQPLqE6lUtETd3aQt/IChNK124YlIjz/AHIM/qc1aiktWQ5PohHk5xUvh+MXOuIOoQnI9z/9b+dMbwlrMnM8roD2MgX9BXUeE/DEtmrzN8wXjIycmtafK3ZO5nLmSu0W7u0McZEakCuX1AtExUfqeK724gfyz8vfnNc3qtrGN7SYGPfFDiuiFz2Pb/gcc/C6zJGP9In/APRhr0SuA+CoVfhnaBOnnzdP+uhrv69Sn8CPJqfGzlfG/wDrvDX/AGHYP/QJK6quV8b/AOu8Nf8AYdg/9Akrqq0IENefDxnqllf3EcgiuYklcKrjaQAxHUf4V6Ca8ev/APkJXX/XeT/0I1z16kqcLx7nPXk42sd3Y+OtNuAou0ltHPUsu5fzH9QK37W9tr1N9pPHMnrG4b+VeO0qO8T74XeNx0ZGKkfiKwjjF9pfcZRxDW57TRXmNl4v1ez2q0y3MY/hmXJ/76HP55robLx9ZyDF/by2x/vJ+8X9Of0rqjWpz2ZvGtBnW0VUs9Usr9A1ndRTZHRWGR9R1FWhWptuLRRRQAUUVQ1u+k03Qr69hVWktoHlVW6EgZ5o2Av0V47/AMLe1r/nxsP++X/+Kpf+Fva1/wA+Nh/3y/8A8VWHt4Dsew0V49/wt7Wv+fGw/wC+X/8AiqF+Letu4VbGwLMcD5X/APiqX1imFmew0V5bqXxM1XS7GOW8trOKV+AjISpPfBD1n/8AC3tZ/wCfKw/75f8A+KrKljaNaPNB6G9TDVadnONr7HsVFeEr8btfaQD7Dp/LY+6//wAVWp/wt7Wv+fGw/wC+X/8Aiq2+sU2dWOyvE4BxVdW5ttbnsVFePf8AC3ta/wCfGw/75f8A+Ko/4W9rX/PjYf8AfL//ABVHt4HnWPYaK8e/4W9rX/PjYf8AfL//ABVaWmfEjWrvxFZ6dd2diizzIjmMNkBsdPm6801WhJ2QWPT653xT4wg8K/YzdWVzcJcuwaSIDZCqgEs5Jwo56nj1Iroao32lafqgi/tKxtbwRNvjFxCsmxvUbhwfethHI6h8WNP0/PmaXfSb7hoLcReW7TFGmDHYGLKB9nkxkDPHvgm+K9hC027Sr/arMkLBATMyzRREbQSw+aePqM9eMjB6eTwxoc/nmbRtPkNy4kn32iN5rDozcckZPJ9all0LSZomjn0yzlSQMHV7dWDBiCwORzkqpPqQPSgDEn8f2kej6Xfx2F2x1GKSZYZNkLRJGMuWMjKoI9M8/TJrNf4sWG1PI0q9lM8hW3AMY81Q8kZb73y4aJuDg4ORnBA66fQ9KurOC0udMs5ra3IMMElurJGRwNqkYGB6UieH9Ijklkj0qyV5pBLIy26Au/PzE45PzHnryfWgDjh8XbFrdZl0i92m3e7ZWeIFYVhimLfe5OyUfKOcgj3q2/xMtRctBHpd3I7zmC3w8Y84i4+zseWymJD/ABYyOR3FbVz4M0C71Czu59LtWazVlij8lNgyEAJXGMqI0APYDFXU0HSo7iW4j02zWaaRZZZBbrukdTlWY4ySDyCelAHCRfG7RrixmuoNL1N0ht1mf9yAAxjWTZuztztcc56/gaszfFGWG+mQ6BdyQwx7WWIiSUTC5kgK7VJyo8stkZOO1daPDOhjP/El07PleTxap/q/7nT7vt0p1x4b0S83G70iwnLbgTLbI2dzb26ju3zH1PPWgCzpeoRarpNrqFtzDdQrMnzA8MARyCQevY4oqeGGO3gSGCNY441CoiKAqgcAADoBRQBh6j4P0zVNUfULnzvPcAHa+BwMdMVAPAmkqeGuP+/g/wAK6ais3ShJ3aNFUnHZnO/8ITpf965/7+//AFqrXPw60O7XE6zt/wBtP/rV1dGKj6vSf2UV7er/ADM4U/CLwuTlorg/9tf/AK1SR/CjwvH0tZT/AL0mf6V22KTFL6vS/lQe3q/zHKR/DnQIh+7gdfowH9Ke3w+0Ruqz/wDfz/61dTijFH1aj/Kg9tU/mOTPw40E/wDLOYfRx/hU6eA9Gjs/syLOEzn/AFnP8q6WjFXGlCDvFEupN7s46T4Z6FICGN5g+k3/ANaqkvwe8MTqVkW8Ibr+/wD/AK1d5RVeziugueXcyPDXhux8KaLHpel+b9njdnHmtubLHJ5+prXooq9iNzlfG/8ArvDX/Ydg/wDQJK6quV8b/wCu8Nf9h2D/ANAkrqqAErx6/wD+Qldf9d5P/QjXsNePX/8AyErr/rvJ/wChGuTF/wAP5nLiNkV6KKK8s4worm7rUfEUOt21gkelH7UsrxsTL8oTbweOp3D8jWjp2q+d4cTU7/ZCBE8k2zO1QpOSM844zVOLtcrlaVzTB2uHU4YdGHBFa1l4p1iwG2O7Myf3Zxv/AF6/rXGSeK7eCKFrmyvImkjM0kZRS1vFuwJJADwD6DJ68cVu9hWkalSnsx3lE9R8Na4+uWMkssKxPE+xtrZB4Bz7da2a5H4e/wDILvP+vn/2Ra66vXi7xTPQptuKbCsnxSM+E9W/685P/QTWtWR4q/5FHVudv+hy8/8AATVFnzyUHak2GpDyD2rlNb8RXukmBIAjhwSS4JPH416GX5HUzJyVG1130OqFByw8699I2v8AM6fYaAh9cVgaP4iuNUtpGaNUljOCMcH0rY0u6lvdNhnuUVJWBDqvQEEj+lGPyCtgI81a1r20Y62HnSpQq3vGezXkQa00jQxb3LfMcZPTiriqwhBxn5c1T1n/AFMX+8f5VfLf6Pn/AGM/pXgqjDnkl0PbxF5ZXhP8U/zRzif6xfqK6LYa51Pvrj1FdNWdCmp3ue3xnpOj6P8AQj2GnbB35qQxuEDlTtPQ0jIyHDAg9eRXVGnS6M/PPaReiY0DHStnwvvbxbpbtkj7XGCx/wB6setbwsT/AMJZpQzx9rj4/wCBCt7JbFH0JXhXj/XdVtvHF/BbaldRQxlAiRzMoUbFPQH1Ne61xeu+CvDGq6xLe6pO0V1KBvAuAucDA4PsK9TLcXh8JWc8QtLWPYyfHYXA13UxSvG1uj107njf/CSa3/0F77/wIf8Axrt/hVrOpX3iieG9vri4j+yswSWUsMhl55+tbn/CuvBX/P6//gUv+FbXhnwn4e0PUJLjRZjLM0ext0wfC5z0H0r18ZnGXV6EqdJe89tEe7j8/wApxOGnRor3mtNEJJ4ture3vNRns7f+zLaa4hG25AnZomZeEYBTuZTgbuhB7nGRB8Wba6tp7uHSb1LVLYyCWUICkoM6mN13ZBJgYAjI55xXUT+D/D13fXV7c6NYy3N5GY7iVoFLSqcZBOOfur+Q9BUUHgTwvbSRvb6Dp8bxRPCjLbqCqNu3KPY73/76PrXyp8UYl18VdMsUkN3puoRES+XCGEQ+0cygsv7zAA8iT72CeMDmt/wv4jHiWzuruO1eCGK6eCIueZUGMPjqM56HkVJeeE9B1C3MF7pNnPEcZSSEEcMzfzdj/wACPrV6y02z07zRYW0Vus0nmSLEgUM2AM4HfCgfhQBaooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigDlfG/+u8Nf9h2D/0CSuqrkPiDdQWSeHrm8njggj1yBpJZXCqg2SckngVq/wDCZeGP+hi0n/wNj/8AiqANmvHr/wD5CV1/13k/9CNamm/HTwy/iS60DX7iHTLyCZkjuBMslrcJ1V1lHC5XBw2MHjJrJvJFlvriSJldGmcqynIYbjyDXJi/4fzOXEbI5o3+uXWsajbacNPSGzkSMG4SQs26NXz8rAfxY/CrWiX99dzahb6ktv51nOsWbYMFYGNX6MSc/NisjxKlxbXk+ox232aJEVXvI9U+zb1HQMuwg4JIHf09KveEWkk0Vnk0uTTvMlZgJ5jLJNkD94xIDZPvzjHsK4ZJclzBpctzJuNaj1XYdU04IsdyqwyQXbpKivK0B5XB3BgMqDjDe1dJeWVhD4dnspQLewS2aNwvSOPaQefYVy8un2Vhq1vdWj6DPdPfBPL+zBZid437XMpy67s9M5FdVrbwR6BfvdxGaBbaQyRg43qFOR+VOdtLBK2ljmrSzXVZbm31G71BLm/jWMy3FmIfPgjzlE64J3kt0PPQV2dcfo11eSeIraDWlSaa2WS3gljkLYYRxuzNwMkrIF3cdOnzV2FTVvewp3vY7z4e/wDILvP+vn/2Ra66uB8G69pGlWNzDqeq2VnI8+5UuLhI2I2ryAT0rpP+Ey8Mf9DFpP8A4Gx/4168PgXovyO2l8CNqsnxUM+EdW/685P/AEE1Tv8AxtoUOnXElhrujz3SRM0MT38ah2A4UnPGTxntXD2Xxr8KeNvCmp2kF0dN1RrR1+xXhCszFSMI3R+fTn2FWann571554rjk/tK3bnYy4B7A5//AFV1Oo6/DFbyrZzA3CtgZQ4689sVu2egW2paTA+rhbp3AlGAUCEjtg16eX8TYfIJOpXi5KWmm/UyxmZ4fL8K6eJ0U2rfLU4S4uptHuZUt7bzmupN8eB1OORxz6VtSXtyul2iufs9w0e+VOhX0FdmmkWcedsX09vxpX0HSJ7dvMtgboniV5HwR9Aeo9f5142d8cYbNKSoU6bj7277fp+JtlvG2UVsdFV3KNJXaTStd9/vZyeqSrNa27o25WJII78VfznT8j/nl/Srus6J5tpbQ6XaW0Qh4bYMNIfUseTWz/Zel/8ACJ+VtcaqIPvbiQZMdPTFeB/bOHp6z1vpprbz9D1sRn2TVsFh40K8bRnLRuzSb6rt5nnlsA1xED0LgfrXSVi2mnXT6gsCxMsiMNxI4X3zW5HpGoo2DJHj3Oa9jB1cIqc3VrRi1sm9/Q93i/H5dOrT58TCLUb2b3T7WuNpSxIAJJCjAHpWiNKG0ZlOcc/LVO+hSxKb5Mh844qMLmGGxdZUaD5pa2Vmfm2DzbB42uqGHfNPWys/8iGtbwt/yN2lf9fcf/oQrF+0Rf8APRfzrW8KTRt4t0ra6n/S4+/+0K9d4atFXcH9zPceGrRV3BpejPoevJPF3/I1XuOm5f8A0EV63XI654m8Kadq8trq6K12gXefsxfGRkc49CK8XMsK8VSUOa2tz5/OMtlmNBUoytZ3POK6r4fnHiCX/rg38xV3/hNPAv8AzwX/AMAz/hWx4c8QeG9WvZIdCRUnWPcw8gx5XOOuPUivJwmUOjXjU9onY8LAcM1cJiYV5VE1F32ObXxvd2n9oXU2s2z3kLMk+jzQhU01fOEayyOo3KgU72LEhhyu0U62+KFxc2jp9it49RwzwwNKwWaMQSOJlOM+Wzx4DY5U+tejBRk+/Wl2CvqT7Y8g1L4qeIdHu743dlYyiDZB5aTBI0cT3MbyF3K8N5CKATwXXqeD6F4V1nUNds7i7v7RLJVuXhih3FnUIxB39s5GOMjit0op7UoAHSgBaKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAhuLSC7j8u7hjnjznZIgYZ+hqt/YOkf8AQLsv/AdP8Kv0UAed6Z8F/DUHie68Ra1Amr6lPMZEE8YEEA6KqRDj5VwMtnkZ4rAvVCahcqoAUTOAAMADca9irx6//wCQldf9d5P/AEI1x4v+H8zlxOyOE1+0lPiI37Sasy26DyhHZxSwRccsu84z/tYyPWtjwtqbatpslx9purhfNKpJdWyQ5AA+6E4Ye/1qpruhazq2pho72yOnx4K2VzC7K7YHL7WG7noDx7Gta0ku7DTpJNdubFRHyHgRoo0QDjO5jXHJ3gl1MG7xscvb+HpFvws9tqTRJOnlP9niASMTmUgnzSTlyuWABwnTNdfcSCTTJnkYWwMT7mnUERjB5YZwR3xnpXEzR2F7r0NraaXpdleJeJJ9pF2hf5XDEbQMliARt9/au11OS5h0m8lsU8y5SB2hXGdzhTgfn2oqXurhLocroAgtfE0Men39hqCTxOJ2s7VUMQRVCbmVjheAMewrtK4/w7eXr+IJoEvry/tixaRrpMBUMUTIw+UYJZnG307DFdhU1fiJnudn4G02xvdOunvLK3ndbjAaWJWIGxfUV1H9haR/0C7L/wAB0/wrA+Hv/ILvP+vn/wBkWuur14fAvRfkd1L4EZF/4csJ9PuIbOysba4kjZY5jao3lsRgNjvg84rz5vhL4W+H/gHXLvTLQ3Oprp8zHULsiSXcEPK54Tn0APqTXrFc/wCPf+Se6/8A9g+f/wBANWbLc+QCctk8nrk167pZzo9n/wBcE/8AQRXkVet6O2/Q7E+tun/oIr5HiL+FD1Z8lxqv3FJ+b/IuUUUV8afmIUUUUAFFFFAXbCsPxIybIF3qHyflzyR64/CtyvPfHUmdfiCtzHAvTt8xr6Xhes8PmlOulflu/wALfqfYcFzdLOqVZfZu/wALfqWK2PCX/I5aR/1+R/8AoQrh7fVbiDAc+avo3X866zwTqcFz4y0dclJDeRYVh/tDvX79HOcJiqE4p2lZ6P0P6U/tTDYmhJJ2dno/Q+pO1eJ/EHStQn8cX80FhdSxP5ZV44WYH92o6geor2we9cR4h+I6aBr1xpv9mNOYQuZPO25yobptPrX5xOHOrH5qjyX+xdV/6Bl7/wCA7/4V2/wr02+tfE1zLdWdxBH9kZd0sTKM7l45Hsa0P+FwL/0Bj/4E/wD2NbnhTx2nijVJLP8As9rZo4jKG83fnBAx0HrWUaHK73HcXVdKu5vFxupdMur+Nvs/2OeG7WJLTaxL7hvB56kqrbh8p4FcvcaX8QdRt7cXweR45YWfd9nQgrPbs+0qxyhVJCAcHAII5Ar1OWSKCJpZ3SONRlndgAPqTUaXlnJIY47mFnEhiKrICQ4XcVx67ecdcc10iPNxL4x0PRIbnXL64hhDMtwsb2imFRLGIwjMAoypfJY47cHFdt4Pur698GaRdasXa9mtI3nMiBGLlQTkAAA+2BWotzbPcNAk8TTLndGHBYYCk8dejL/30PWpqACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigBK8ev/wDkJXX/AF3k/wDQjXsNePX/APyErr/rvJ/6Ea5MX/D+Zy4jZFeqeq2B1HTnt0k8p9ySRvt3bXRg6kjjIyoyKuUV5ezuci0ZyUHhnWUs4LGfULF7SO9F2wS1YOf3vmYBLnHPfGa62iiqlJy3G5OW4ZJ6milRWkkEcas8jdEUZJ/AVtWXhHV73k24tk/vTnH6Dn+VXGjUnsgUZS2Oh+Hv/ILvP+vn/wBkWuurH8O6GdCs5IWm85pH3sQuADgDHX2rYr2Iq0Uj0aaaikwrn/Hf/JPtf/7B8/8A6Aa6CsDx3/yT/X8/9A6f/wBANUaLc+Pq9P8ADWoWlzo9rBDOjTQwqrx55UgY6V5gKWORopA8TlHU5DKcEV4+YYFY2moN2aOTOspjmlFU3Llad1/wT2eivOdN8a6hZKI7nF2gPVzh/wA/8a6zTvFel36DM620neOY4/I9DXxmJyrE4fVxuu6PzDHcPY/BXbhzR7rX/gm1RWZJ4j0eMkNqEJx/dO7+VUp/GujxA+XLJMc9EjP9cVywwWJn8MH9x59PK8dVfuUpP5M6CiuOn+IEI/49rF3/AOukgX+WapTePr5v9TbW8f8AvZb/AArthkuMn9m3q0erS4XzOp9i3q0d47rHGzudqqMknsBXk+s3/wDaesXF0udjthAeyjgVPd+JtWvUeOa7IjcEMiKFBB7cVlZr6TKsslg3KdR3b7H2/D+QzyyUqtZpyeit0XUK6DwH/wAlC0H/AK/4f/QxXP5rf8Cf8lB0H/r/AIf/AEMV7yPrZbH2BXlvjHwPrmr+K7u/sII5IJtm0mUKeEAPB9xXqVeGfEX4reJvDnjy/wBJ0uS2S2thGFDw7mO6NWJJPu1at2OGMXJ2RL/wrXxN/wA+cX/f9f8AGup8AeENX0DXZ7rU4Y442tzGu2QMSSynt9K8p/4Xl40/5+LT/wABhXd/Cb4k6/4v8T3On609vJClo0yGOLYwYMo9fRqSkmW6Ukrs9W1XT4dX0a8065yIbuB4XK9QGBGR78151efDDU5bZjHqkTT3EO66VgQstw8u6ZwSrAAoNgyrcdRXb+JvElt4W0gahfRSyxmVIQkTIpLMcDl2VQPckVSsvHmhzrGLyf8As6aSVYo4bp03MWSNgQUZlIxNGM5xlgO4zRkVvCHhK90Ga3kv7yO5kitfIdlzl28q2TPP/XAn8RXX1i2vjDw9e3EVvaatbTTTSGOONGyztgHgemCDnpjnNbVABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAhrx6//AOQldf8AXeT/ANCNFFcmL/h/M5cRsivT4IZbqTy7aJ5pP7kalj+lFFcdCnGpKzOWKu7G7ZeC9Wu9rTLHaRnqZWyw/wCAj+pFdDZeBNOgO68klu2/uk7F/Ic/rRRXpRpQhsjujSglc6C1sLSyjCWltFCvoigZqyKKK1NkFFFFABVHWtMj1rQ73TJpGjjvIHhZ0xlQykZGe/NFFAHlv/DO+i/9BvUv++Y//iaP+Gd9F/6Depf98x//ABNFFKyL9pLuH/DO+i/9BvUv++Y//iaP+Gd9Fx/yG9R/75j/APiaKKOVB7SXcP8AhnfRe+t6l/3zH/8AE0f8M76L/wBBvUv++Y//AImiiiyH7SfcP+Gd9F/6Depf98x//E0f8M76L/0G9S/75j/+Joooshe0n3D/AIZ30X/oN6l/3zH/APE0f8M76L/0G9S/75j/APiaKKOVB7SfcP8AhnfRf+g3qX/fMf8A8TV3RvgVpGi63ZanDq9/JJZzLMqOqbWKnODhelFFFkHtJdz1IdK8s8ZfBZfFviu71oa61obrZmL7J5m0qip13j+7npRRQyVJxd0Yf/DOQ/6Gg/8AgB/9srq/h/8ACdfAmuT6l/bBvmltzAE+zeWFyynOdxz92iijlSKdSTVmdtquj2usw28d5uKQXCXCqMYZlOQDkHisi+8CaZfX8t0bi8g+0PmeKF1VJo9kamIgqfkxCh4wevODiiimQGjeA9M0XVotRhuby4uYYTbxNcSKdkOAFjGFHC4OCeeTkmumAwKKKACiiigAooooA//Z)\n",
        "\n",
        "**Hypothesis:** We hypothesize that cognitive representations encoding structural relations (as suggested by recent studies on PPA) will better align with scene parsing than scene classification DNN representations. This approach enables us to investigate brain region functions using cognitive modeling.\n",
        "\n",
        "\n",
        "## Roadmap\n",
        "\n",
        "\n",
        "1.   **Loading Models**: Loading Scene Classification and Scene Parsing models into `Net2Brain`\n",
        "2.   **Feature Generation**: Extracting model feautures using the `BonnerPnas2017`-Dataset\n",
        "3. **RDM Creating**: Turning the features from both models into one RDM per network layer\n",
        "4. **Evaluation through RSA**: Comparing model to PPA-representations using RSA\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mu4sYz1tLpRL"
      },
      "source": [
        "# Load the Dataset\n",
        "> Bonner Michael F, Epstein Russell A. Coding of navigational affordances in the human visual system. Proceedings of the National Academy of Sciences. 2017;114(18):4793–4798. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from net2brain.utils.download_datasets import DatasetBonnerPNAS2017\n",
        "from pprint import pprint\n",
        "\n",
        "paths = DatasetBonnerPNAS2017.load_dataset()\n",
        "pprint(paths)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract the paths we need\n",
        "\n",
        "stimuli_path = paths[\"stimuli_path\"]\n",
        "roi_path = paths[\"PPA_Study\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zoD_SmGWUxX_"
      },
      "source": [
        "# Step 1: Using FeatureExtractor with a pretrained DNN\n",
        "1. Scene Classification ([Places365 CSAILVision](https://github.com/CSAILVision/places365))\n",
        "2. Scene Parsing Model ([Semantic Segmentation CSAILVision](https://github.com/CSAILVision/semantic-segmentation-pytorch)) \n",
        "\n",
        "\n",
        "To extract activations from a pretrained model in one of the netsets, you must first initialize the `FeatureExtractor` class and specify the name of the model as well as the netset it belongs to. \\\\\n",
        "Additionally, you can choose the device on which the extraction is computed, with either `cpu` or `cuda`.\n",
        "\n",
        "If you want to implement **your own model**, save the model in a variable and put it into the Feature Extractor like:\n",
        "`FeatureExtractor(model=my_model, device='cuda')`\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZSZWRMLWRFLx"
      },
      "outputs": [],
      "source": [
        "from net2brain.feature_extraction import FeatureExtractor\n",
        "\n",
        "fx_class = FeatureExtractor(model='Places365', \n",
        "                            netset='Toolbox', \n",
        "                            device='cuda')\n",
        "\n",
        "fx_parsing = FeatureExtractor(model='SceneParsing',\n",
        "                              netset='Toolbox', \n",
        "                              device='cuda')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### How are the models different?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "fTE6x7WxMB3Z"
      },
      "outputs": [],
      "source": [
        "#@title Code for visualizaion\n",
        "# System libs\n",
        "import numpy as np\n",
        "import scipy.io\n",
        "import PIL.Image\n",
        "import torchvision.transforms\n",
        "import torch\n",
        "from mit_semseg.utils import colorEncode\n",
        "import os\n",
        "CUDA_LAUNCH_BLOCKING=1\n",
        "\n",
        "# Navigate up one directory from stimuli_data and into the etc directory\n",
        "etc_path = os.path.join(stimuli_path, os.pardir, \"etc\")  \n",
        "\n",
        "# Construct paths for the files\n",
        "color_file_path = os.path.join(etc_path, \"color150.mat\")\n",
        "image_file_path = os.path.join(etc_path, \"ADE_val_00001193.jpg\")\n",
        "\n",
        "# Get colors\n",
        "colors = scipy.io.loadmat(color_file_path)['colors']\n",
        "\n",
        "def visualize_result(img, scores, index=None):\n",
        "\n",
        "    _, pred = torch.max(scores, dim=1)\n",
        "    pred = pred.cpu().numpy()[0]\n",
        "    if index is not None:\n",
        "        pred = pred.copy()\n",
        "        pred[pred != index] = -1\n",
        "\n",
        "    pred_color = colorEncode(pred, colors).astype(np.uint8)\n",
        "    img = img.astype(np.uint8)\n",
        "    im_vis = np.concatenate((img, pred_color), axis=1)\n",
        "    display(PIL.Image.fromarray(im_vis))\n",
        "\n",
        "# Load and normalize one image as a singleton tensor batch\n",
        "pil_to_tensor = torchvision.transforms.Compose([\n",
        "    torchvision.transforms.ToTensor(),\n",
        "    torchvision.transforms.Resize((224, 224)),\n",
        "    torchvision.transforms.Normalize(\n",
        "        mean=[0.485, 0.456, 0.406],\n",
        "        std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "pil_image = PIL.Image.open(image_file_path).convert('RGB')\n",
        "img_data = pil_to_tensor(pil_image)\n",
        "input_image = img_data.unsqueeze(0).cuda()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "5fD3KtWbNxJ1"
      },
      "outputs": [],
      "source": [
        "#@title Testing the models\n",
        "\n",
        "# Run Scene Classification Model from toolbox\n",
        "scores_scene_classification = fx_class.model(input_image)\n",
        "_, pred = torch.max(scores_scene_classification, dim=1)\n",
        "print(\"Scene Classificaion:\", pred) # orchard 249\n",
        "\n",
        "\n",
        "# Run Scene Parsing Model from toolbox\n",
        "scores_scene_parsing = fx_parsing.model(input_image) \n",
        "visualize_result(np.array(pil_image.resize((224, 224))), scores_scene_parsing)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HP-p77eFH7Mf"
      },
      "source": [
        "This initializes the feature extractor and loads the model and any specified layers for extraction into the instance. To view the layers that are set to be extracted, you can execute `fx.layers_to_extract`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nhXqO0Bx1qqe"
      },
      "outputs": [],
      "source": [
        "fx_class.layers_to_extract"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ntKeDWmuIi9w"
      },
      "source": [
        "Note that the suggested layers may not be exhaustive. To view a complete list of all available layers, you can use `fx.get_all_layers()` and overwrite the `layers_to_extract` attribute with your desired subset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c3SGIaHXJHpP"
      },
      "outputs": [],
      "source": [
        "fx_class.get_all_layers()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ssVK6gFQUi-H"
      },
      "source": [
        "### Extracting Layer features\n",
        "To extract weights from the layers, you can use the `fx.extract()` function and provide the path to the images that you want to run through the network. You can choose between the 'npz', 'pt', or 'dataset' formats, but it is recommended to use 'npz' if you plan to use the other steps in the toolbox.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "972RH2jd1uhY"
      },
      "outputs": [],
      "source": [
        "# Create features for the Scene Classification model\n",
        "fx_class.extract(data_path=stimuli_path, \n",
        "                 save_path='Classification_Feats',\n",
        "                 layers_to_extract=['model.4', 'model.5', 'model.6', 'model.7', 'model.9'])\n",
        "\n",
        "# Create features for the Scene Parsing model\n",
        "fx_parsing.extract(data_path=stimuli_path, \n",
        "                   save_path='Parsing_Feats')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ESxU8jO6WQMd"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mIg8FGmD2cN6"
      },
      "source": [
        "# Step 2: Creating RDMs from Layer Features\n",
        "In Step 1 of the process, the Feature Extractor extracts features that are used here in Step2 to calculate Representational Dissimilarity Matrices (RDMs) through the built-in functionality of the RDM creator. To do this, the RDM creator function requires the path to the location of the .npz files containing all the layer features for each image in a [Batch x Channel x Height x Width] format. The function then produces an RDM in the shape of (#Images,#Images) for each layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wQNy9Egm2iJU"
      },
      "outputs": [],
      "source": [
        "from net2brain.rdm_creation import RDMCreator\n",
        "\n",
        "# Create RDMs for the Scene Classification model\n",
        "creator_class = RDMCreator()\n",
        "creator_class.create_rdms(feature_path=\"Classification_Feats\", save_path=\"Classification_RDMs\", save_format='npz') \n",
        "\n",
        "# Create RDMs for the Scene Parsing model\n",
        "creator_parsing = RDMCreator()\n",
        "creator_parsing.create_rdms(feature_path=\"Parsing_Feats\", save_path=\"Parsing_RDMs\", save_format='npz') \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PDDuP4AMYOdj"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F3J0pnmbWBX-"
      },
      "source": [
        "# Step 3: Performing RSA on the Model RDMs and the ROI RDMs\n",
        "This tutorial demonstrates how to utilize the evaluation features of Net2Brain and plot the resulting data. You have the option to select from three different metrics for evaluation: \"RSA\", \"Weighted RSA\", and \"Searchlight\". Each module returns a pandas dataframe that can be easily integrated into the toolbox's integrated plotting functionality."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xZ6xZij_2rHd"
      },
      "outputs": [],
      "source": [
        "from net2brain.evaluations.rsa import RSA\n",
        "\n",
        "# Get path to RDMs\n",
        "model_rdms = r\"/content/Classification_RDMs\"\n",
        "\n",
        "# Start RSA\n",
        "sc_evaluation = RSA(model_rdms, \n",
        "                 roi_path, \n",
        "                 model_name=\"Scene Classification\")\n",
        "\n",
        "df_classification = sc_evaluation.evaluate() # Evaluation - Returns a pandas dataframe\n",
        "\n",
        "\n",
        "\n",
        "# Get path to RDMs\n",
        "model_rdms = r\"/content/Parsing_RDMs\"\n",
        "\n",
        "# Start RSA\n",
        "sp_evaluation = RSA(model_rdms, \n",
        "                 roi_path, \n",
        "                 model_name=\"Scene Parsing\")\n",
        "\n",
        "df_parsing = sp_evaluation.evaluate() # Evaluation - Returns a pandas dataframe\n",
        "\n",
        "display(df_classification)\n",
        "display(df_parsing)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c6AfKmA73OH3"
      },
      "outputs": [],
      "source": [
        "# Comparing statistical significance\n",
        "ttest, sig_pairs = sc_evaluation.compare_model(sp_evaluation)\n",
        "print(sig_pairs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UFT3HH9VYWbe"
      },
      "source": [
        "### Visualizing RSA Evaluation Results\n",
        "\n",
        "If you would like to visualize the evaluation results, you can do so using the integrated plotting functionality of the toolbox. To do this, initialize the class with a list of dataframes that were returned through the evaluation. It is important to ensure that each dataframe contains the same ROIs, indicating that each test was conducted on the same brain RDMs. Additionally, each dataframe should contain a different model name, which can be set manually or through the \"model_name\" parameter during evaluation (as described above).\n",
        "\n",
        "The following example illustrates how to plot the data using a single dataframe.\n",
        "\n",
        ">Note: Multiple ways of plotting are planned for implementation in the future. For now, only the \"best_layer\" variant is available, which plots the best performing layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qD-iK0DF3hW2"
      },
      "outputs": [],
      "source": [
        "from net2brain.evaluations.plotting import Plotting\n",
        "\n",
        "# Plotting with significance\n",
        "plotter = Plotting([df_classification, df_parsing])\n",
        "results_dataframe = plotter.plot(pairs=sig_pairs, metric = \"R\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DkcD1-zMgzSx"
      },
      "source": [
        "## Let us add random weights!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WQ7IztjyNaXa"
      },
      "outputs": [],
      "source": [
        "## Feature Extraction ##\n",
        "\n",
        "fx_class_random = FeatureExtractor(model='Places365', \n",
        "                                   netset='Toolbox', \n",
        "                                   device='cuda',\n",
        "                                   pretrained=False)\n",
        "\n",
        "fx_class_random.extract(data_path=stimuli_path, \n",
        "                        save_path='Classification_Feats_random')\n",
        "\n",
        "fx_parsing_random = FeatureExtractor(model='SceneParsing',\n",
        "                                     netset='Toolbox', \n",
        "                                     device='cuda',\n",
        "                                     pretrained=False)\n",
        "\n",
        "fx_parsing_random.extract(data_path=stimuli_path, \n",
        "                          save_path='Parsing_Feats_random')\n",
        "\n",
        "\n",
        "## RDM Creation ##\n",
        "\n",
        "\n",
        "\n",
        "creator = RDMCreator()\n",
        "creator.create_rdms(feature_path=\"Classification_Feats_random\", save_path=\"Classification_RDMs_random\", save_format='npz') \n",
        "\n",
        "creator = RDMCreator()\n",
        "creator.create_rdms(feature_path=\"Parsing_Feats_random\", save_path=\"Parsing_RDMs_random\", save_format='npz') \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## Evaluation ##\n",
        "evaluation = RSA(\"/content/Classification_RDMs_random\", \n",
        "                 roi_path, \n",
        "                 model_name=\"Scene Classification (random)\")\n",
        "\n",
        "df_classification_rdm = evaluation.evaluate() # Evaluation - Returns a pandas dataframe\n",
        "\n",
        "\n",
        "\n",
        "evaluation = RSA(\"/content/Parsing_RDMs_random\", \n",
        "                 roi_path, \n",
        "                 model_name=\"Scene Parsing (random)\")\n",
        "\n",
        "df_parsing_rdm = evaluation.evaluate() # Evaluation - Returns a pandas dataframe\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wzV5pNAsN-kX"
      },
      "outputs": [],
      "source": [
        "# Plotting with significance\n",
        "plotter = Plotting([df_classification, df_parsing, df_classification_rdm, df_parsing_rdm])\n",
        "results_dataframe = plotter.plot(pairs=sig_pairs, metric=\"R\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "PhXmDhmt6Gd8"
      ],
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
